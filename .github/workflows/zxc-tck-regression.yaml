# SPDX-License-Identifier: Apache-2.0
name: "ZXC: TCK Regression"
on:
  workflow_call:
    inputs:
      ref:
        description: "The branch, tag, or SHA to checkout:"
        required: false
        type: string
      custom-job-name:
        description: "The custom job name to use for the job:"
        required: false
        type: string

defaults:
  run:
    shell: bash

permissions:
  checks: write
  contents: read

env:
  SOLO_CLUSTER_NAME: "solo-tck-e2e"
  SOLO_NAMESPACE: "solo-tck-e2e"
  SOLO_DEPLOYMENT: "solo-tck-deployment"
  SOLO_CLUSTER_SETUP_NAMESPACE: "solo-setup"
  GRADLE_EXEC: ionice -c 2 -n 2 nice -n 19 ./gradlew

jobs:
  # Execute TCK Regression Tests using specified version of hiero-consensus-node
  tck-regression:
    name: ${{ inputs.custom-job-name || 'Standard' }}
    runs-on: hiero-network-node-linux-large
    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@4d991eb9b905ef189e4c376166672c3f2f230481 # v2.11.0
        with:
          egress-policy: audit

      #  Check out the specified hiero-consensus-node reference
      - name: Checkout Consensus Node
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          ref: ${{ inputs.ref || '' }}
          fetch-depth: 0

      #  Checkout the sdk-tck repository and the TCK SDK Client
      - name: Checkout Regression Code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          path: platform-sdk/regression
          repository: hiero-ledger/hiero-sdk-tck
          fetch-depth: "1"

      # Checkout the JS-SDK server
      - name: Checkout JS-SDK Server
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          path: platform-sdk/sdk-server
          repository: hiero-ledger/hiero-sdk-js
          fetch-depth: "1"

      # Set up Java Environment
      - name: Setup Java
        uses: actions/setup-java@c5195efecf7bdfc987ee8bae7a71cb8b11521c00 # v4.7.1
        with:
          distribution: temurin
          java-version: 21.0.6

      # Set up the node environment
      # Version 20.18.0 is the recommended version for solo.
      - name: Setup NodeJS Environment
        uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020 # v4.4.0
        with:
          node-version: 20.18.0

      - name: Setup PNPM
        run: |
          npm install -g pnpm

      # Set up the gradle environment
      - name: Setup Gradle
        uses: gradle/actions/setup-gradle@8379f6a1328ee0e06e2bb424dadb7b159856a326 # v4.4.0
        with:
          cache-read-only: false

      # Build the hiero-consensus-node artifacts
      - name: Build hiero-consensus-node
        run: ${GRADLE_EXEC} assemble

      # Set up the npm dependencies and cache on the tck-client
      - name: Set up the tck-client
        run: |
          npm cache clean --force
          npm install
        working-directory: platform-sdk/regression

      # Set up the npm dependencies and cache on the sdk-server
      - name: Install NodeJS Dependencies (sdk-server)
        id: start-sdk-server
        run: |
          pnpm add @hashgraph/sdk@^2.63.0-beta.1 long@^5.2.3 @hashgraph/proto@^2.17.0-beta.1
          pnpm install
          nohup pnpm start &
          server_pid=$!
          echo "pid=${server_pid}" >> "${GITHUB_OUTPUT}"
        working-directory: platform-sdk/sdk-server/tck

      # Install solo and configure to use the artifacts from
      # the hiero-consensus-node build
      - name: Install Solo
        run: npm install -g @hashgraph/solo@0.37.1

      # Set up kind; needed for configuring the solo environment
      - name: Setup Kind
        uses: helm/kind-action@a1b0e391336a6ee6713a0583f8c6240d70863de3 # v1.12.0
        with:
          install_only: true
          node_image: kindest/node:v1.31.4@sha256:2cb39f7295fe7eafee0842b1052a599a4fb0f8bcf3f83d96c7f4864c357c6c30
          version: v0.26.0
          kubectl_version: v1.31.4
          verbosity: 3
          wait: 120s

      # Set up solo
      - name: Configure and run solo
        run: |
          kind create cluster -n "${{ env.SOLO_CLUSTER_NAME }}"
          solo init
          solo cluster-ref connect --cluster-ref kind-${{ env.SOLO_CLUSTER_NAME }} --context kind-${{ env.SOLO_CLUSTER_NAME }}
          solo deployment create -n "${{ env.SOLO_NAMESPACE }}" --deployment "${{ env.SOLO_DEPLOYMENT }}"
          solo deployment add-cluster --deployment "${{ env.SOLO_DEPLOYMENT }}" --cluster-ref kind-${{ env.SOLO_CLUSTER_NAME }} --num-consensus-nodes 1
          solo node keys --gossip-keys --tls-keys -i node1 --deployment "${{ env.SOLO_DEPLOYMENT }}"
          solo cluster-ref setup -s "${{ env.SOLO_CLUSTER_SETUP_NAMESPACE }}"
          solo network deploy -i node1 --deployment "${{ env.SOLO_DEPLOYMENT }}"
          solo node setup -i node1 --deployment "${{ env.SOLO_DEPLOYMENT }}" --local-build-path ./hedera-node/data
          solo node start -i node1 --deployment "${{ env.SOLO_DEPLOYMENT }}"
          solo mirror-node deploy --deployment "${{ env.SOLO_DEPLOYMENT }}" --cluster-ref kind-${{ env.SOLO_CLUSTER_NAME }}

          kubectl port-forward svc/haproxy-node1-svc -n "${{ env.SOLO_NAMESPACE }}" 50211:non-tls-grpc-client-port &
          kubectl port-forward svc/mirror-monitor -n "${{ env.SOLO_NAMESPACE }}" 5600:http &
          kubectl port-forward svc/mirror-rest -n "${{ env.SOLO_NAMESPACE }}" 5551:http &
          kubectl port-forward svc/mirror-restjava -n "${{ env.SOLO_NAMESPACE }}" 8084:http &

      # Start the TCK client
      - name: Start tck-client
        env:
          OPERATOR_ACCOUNT_ID: "0.0.2"
          OPERATOR_ACCOUNT_PRIVATE_KEY: "302e020100300506032b65700422042091132178e72057a1d7528025956fe39b0b847f200ab59b2fdd367017f3087137"
          JSON_RPC_SERVER_URL: "http://127.0.0.1:8544"
          NODE_IP: "127.0.0.1:50211"
          MIRROR_NODE_REST_URL: "http://127.0.0.1:5551"
          MIRROR_NODE_REST_JAVA_URL: "http://127.0.0.1:8084"
        run: |
          solo account create --dev --ed25519-private-key "${{ env.OPERATOR_ACCOUNT_PRIVATE_KEY }}" --deployment ${{ env.SOLO_DEPLOYMENT }} --hbar-amount 1000000
          cp .env.custom_node .env
          npm run test
        working-directory: platform-sdk/regression # required

      - name: SDK TCK Regression Test Report
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        if: ${{ !cancelled() }}
        with:
          name: SDK TCK Regression Test Report
          path: "**/platform-sdk/regression/mochawesome-report/mochawesome.*"
          retention-days: 7

      # Collect run logs in a log file, ignore last job as it is the one that runs this workflow
      - name: Collect run logs in a log file
        continue-on-error: true
        env:
          GH_TOKEN: ${{ secrets.GH_ACCESS_TOKEN }}
        run: |
          for job_id in $(gh run view ${{ github.run_id }} --json jobs --jq '.jobs | map(.databaseId) | .[0:-1] | .[]'); do
            echo "Fetching logs for job ${job_id}..."

            current_job_name=$(gh run view ${{ github.run_id }} --json jobs | jq --argjson job_id "${job_id}" -r '.jobs[] | select(.databaseId == ${job_id}) | .name')

            echo "Logs for job $current_job_name :" >> run.log

            gh api \
            -H "Accept: application/vnd.github+json" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            /repos/hiero-ledger/hiero-consensus-node/actions/jobs/"${job_id}"/logs >> run.log
          done

      - name: Upload log as artifact
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        continue-on-error: true
        with:
          name: Run Logs
          path: run.log

      # Stop the TCK server
      - name: Stop tck-server
        if: ${{ always() }}
        run: |
          echo ${{ steps.start-sdk-server.outputs.pid }}
          kill -9 ${{ steps.start-sdk-server.outputs.pid }}

      # Stop the solo nodes
      - name: Stop solo
        if: ${{ always() }}
        run: |
          kind delete cluster -n ${{ env.SOLO_CLUSTER_NAME }}
